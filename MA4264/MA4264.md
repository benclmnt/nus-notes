MA4264 - Game Theory

Tools for multi-person decision making: cooperative & competitive

Vocabulary:
- **Complete Information**: Everyone knows each other's payoff function (payoff functions are common knowledge)
- **Perfect Information**: At each move of the game, the player with the move knows the full history of the play of the game so far. ^2f023a
- **Static Games**: one-stage decision making

Keywords: Nash Equlibrium (ch. 1), subgame-perfect Nash Equilibrium (ch. 2)
Bayesian Nash Equilibrium (ch. 3), Perfect Bayesian Equilibrium (ch. 4), Nash Bargaining Solution & Shapley Value (ch. 5)

# 1 Static Games with Complete Information

- Let $S_i$ denote the set of strategies (**strategy space**) available to player $i$ and $s_i$  be an arbitrary member of this set. 
- Let $u_i$ be player $i$'s payoff function, i.e. $u_i(s_1, \dots, s_n)$ is the payoff to player $i$ if the players choose strategies $(s_1, \dots, s_n)$.

**Def 1.1** The **normal-form** (or strategic-form) representation of an $n$-player game is denoted as $G = \{ S_1, \dots, S_n; u_1 \dots, u_n \}$. -> (players, strategies, payoff)

**Def 1.2** Let $s_i', s_i'' \in S_i$. Strategy $s_i'$ is **strictly dominated** by $s_i''$ if for all combination of other players' strategies, $u_i(s_1, \dots, s_{i-1}, s_i', s_{i+1}, \dots, s_n) < u_i(s_1, \dots, s_{i-1}, s_i'', s_{i+1}, \dots, s_n)$. 

Rational players do not play strictly dominated strategies.

We could apply iterations of eliminating strictly dominated strategies (**IESDS**) , but there might be cases where (1) no such strategy are left and (2) we need to assume it is common knowledge that all players are rational.

**Def 1.3.** The **best response** for player $i$ to a combination of other players' strategies $s_{-i} \in S_{-i}$, denoted by $R_i(s_{-i})$, is the set of $s_i$ that maximizes $u_i(s_i, s_{-i})$.

**Def 1.4 (Nash Equilibrium  / NE)**. Strategies $(s_1^*, \dots, s_n^*)$ are a **Nash equilibrium** if $s_i^* \in R_i(s_{-i}^*)$ for $i = 1, \dots, n$.

Based on def 1.4, there are 2 ways to find NE:
1. For any guess $(s_1^*, s_2^*) \in S_1 \times S_2$, compute $R_1(s_2^*)$ and $R_2(s_1^*)$. Then $(s_1^*, s_2^*)$ is an NE if $s_1^* \in R_1(s_2^*)$ and $s_2^* \in R_2(s_1^*)$
2. Compute $R_1(s_2)$ for all $s_2 \in S_2$ and $R_2(s_1)$ for all $s_1 \in S_1$ and calculate the intersection.

Some results:
- A game can have multiple NE
- If game theory's solution to a game is unique, then solution is NE.
- (Nash, 1950) In any finite game, there exists at least 1 NE.

**The relation between NE and IESDS:**
- If the strategies $(s_1^*, \dots, s_n^*)$ are NE, then they survive iterated elimination of strictly dominated strategies. (In other words, NE $\subset$ IESDS)
- If iterated elimination of strictly dominated strategies eliminates all but the strategies $(s_1^*, \dots, s_n^*)$ then these strategies are the unique NE of the game

## Applications

### Cournot Model of Duopoly

Let $q_1$ and $q_2$ be the quantities of the **same** product produced by firms 1 and 2, respectively, which costs $c$ to produce. 

(The two firms can set different prices, but the one with higher price will lose all market since it's the same product, so we can assume that they sell at the same market-clearing price.) Let $P(Q) = a - Q$ be the market-clearing price when the total quantity on the market is $Q = q_1 + q_2$, and $a$ the reservation price, i.e. the highest price a customer is willing to pay for the product.

Then the profit is $q_i[a - (q_i + q_j) - c]$. 

Suppose $(q_1^*, q_2^*)$ is a NE. Then $q_i^*$ maximizes $q_i[a - (q_i + q_j^*) - c]$ for a given $q_j^*$. Hence, $q_i^* = \frac{a - q_j^* - c}{2}$  for $i \in \{1, 2\}$. Solving, we get $q_1^* = q_2^* = \frac{a - c}{3}$.

For a monopoly, the optimal quantity (based on game theory) is $Q^M = \frac{a-c}{2}$, which is less than $Q^D = 2 \times \frac{a-c}{3}$. This means there is less supply, and hence higher prices in the monopoly case.

Additional results. 
- (T1 Q6) In the general case of $n$ oligopolists, the Cournot quantity is $q_C = \frac{a-c}{n + 1}$
- (T1 Q7) If the costs are $(c_1, c_2)$ then the firms should produce 
	- $(\frac{a - 2c_1 + c_2}{3}, \frac{a - 2c_2 + c_1}{3})$ if $0 < c_1, c_2 < \frac{a}{2}$ (i.e. $a - c_2 > \frac{a-c_1}{2}$)
	- $(\frac{a-c_1}{2}, 0)$ if $0 < c_1 < c_2 < a, \; a - c_2 \le \frac{a-c_1}{2}$, i.e. $c_1$ is much smaller than $c_2$.


### Bertrand Model of Duopoly

Suppose now the two firms produce different products (that is somewhat substitutable)

If firms 1 and 2 chooses price $p_1$ and $p_2$, respectively, the quantity that consumers demand from firm $i$ is $q_i(p_i, p_j) = a - p_i + bp_j$ where $b > 0$ reflects the extent to which firm $i$'s product is a substitute for firm $j$'s product.

The profit is now $\pi_i(p_i, p_j) = (a - p_i + bp_j) \cdot (p_i - c)$. Taking first-order derivatives, we obtain $p_1^* = p_2^* = \frac{a+c}{2 - b}$.

### Problem of the Commons

The problem of the commons basically states that if one considers only his own incentives, and not the effect of his actions on other individuals, it will result in overutilization of public resources and underutilization of public goods.

### Final-Offer Arbitration

Setting: A union and a firm are embroiled in a wage dispute. Both sides make their offers $w_u$ and $w_f$. Next, an arbitator chooses one of the two offers as the settlement by choosing the settlement that is closer to his own ideal settlement (not known to either parties). Game Theory concludes that if there is more uncertainty about the arbitrator's preferred settlement, the parties can afford to be more aggressive.

### Zero-Sum Game

A two-person game is a zero-sum game (also called a matrix game) if $u_1(s_1, s_2) = -u_2(s_1, s_2)$ for all $s_1 \in S_1$ and $s_2 \in S_2$. Then $(s_1^*, s_2^*)$ is an NE if $u_1(s_1, s_2^*) \le u_1(s_1^*, s_2^*) \le u_1(s_1^*, s_2)$, (i.e. NE is the minimum payoff for player $1$ in its row and maximum payoff in its column)

### Mixed Strategies

**Def 1.5** In the normal-form game $G = \{ S_1, \dots S_n; u_1, \dots, u_n \}$, suppose $S_i= \{s_{i1}, \dots, s_{iK} \}$. Then each strategy $s_{ik}$ in $S_i$ is called a pure strategy for player $i$. A **mixed strategy** for player $i$ is a probability distribution $p_i = (p_{i1}, \dots, p_{iK})$ where $p_{i1} + \dots + p_{iK} = 1$ and $p_{ik} \ge 0$

So far, we have only talked about pure strategies, i.e. where $p_i = (0, \dots, 0, 1, 0, \dots ,0)$. We can extend the definition of NE to require each player's mixed strategy be a best response to other players' mixed strategy.

Note that a pure strategy may be 
1. strictly dominated by a mixed strategy
2. a best response to a mixed strategy despite it not being a best response to any pure strategy.

Let $S_1= \{s_{11}, \dots, s_{1J} \}$ and $S_2= \{s_{21}, \dots, s_{2K} \}$. If player 2 believes that player 1 will play the strategies $(s_{11}, \dots, s_{1J})$ with probabilities $(p_{11}, \dots, p_{1J})$, then player 2's expected payoff of playing the strategies $(s_{21}, \dots, s_{2K})$ with probabilities $(p_{21}, \dots, p_{2K})$ is $$v_2(p_1, p_2) = \sum\limits_{k=1}^K \sum\limits_{j=1}^J p_{2k} \cdot p_{1j} \cdot u_2(s_{1j}, s_{2k})$$
**Def 1.6** In the two-player normal-form game $G = \{S_1, S_2; u_1, u_2 \}$, the mixed strategies $(p_1^*, p_2^*)$ are a **Nash Equilibrium** if each players' mixed strategy is a best response to the other player's mixed strategy, i.e. $p_1^*$ satisfy $v_1(p_1^*, p_2^*) \ge v_1(p_1, p_2^*)$ for every probability distribution $p_1$ over $S_1$ and  $p_2^*$ satisfy $v_2(p_1^*, p_2^*) \ge v_2(p_1^*, p_2)$ for every probability distribution $p_2$ over $S_2$.

It is worth emphasizing that such a mixed-strategy NE does not rely on any randomness (flipping coins / rolling dice). Rather, we interpret player $j$'s mixed strategy as a statement of player $i$'s uncertainty about player $j$'s choice of (pure) strategy. 

Note that each player's best-response correspondence always includes (the appropriate generalizations of) the limit from the left, the limit from the right and all the values in between. This is because if player $i$ has several pure strategies that are best responses to the other players' mixed strategies, then any mixed strategy $p_i$ that puts all its probability on some or all of player $i$'s pure-strategy best responses is also a best response for player $i$.

If there are more than 2 strategies for a player, we can first eliminate strictly dominated strategies.

Result. 
- (T2 Q5) If a pure strategy $s_{kj} \in S_{kj}$ is elimianated by IESDS, then the strategy will be played with zero probability, i.e. $p_{kj} = 0$ in any mixed strategy NE.

**Theorem 1.1** *(Nash, 1950)* In the $n$-player normal-form game $G = \{ S_1, \dots S_n; u_1, \dots, u_n \}$. If $n$ is finite and $S_i$ is finite for every $i$, then there exists at least 1 NE, possibly involving mixed strategies.

# 2 Dynamic Games of Complete Information

![[MA4264#^2f023a]]

## 2.1 Complete and Perfect Information

Def. **Action space** $A$ is the set of all actions that can be taken by a player.

**2.1A** Assume the setting of a game where (1) Player 1 chooses an action $a_1$ from action space $A_1$. (2) Player 2 observes $a_1$ and then chooses an action $a_2$ from action space $A_2$. (3) Payoffs are $u_1(a_1, a_2)$ and $u_2(a_1, a_2)$.  ^461de6

**Backwards Induction**

At the second stage, player 2 observes $a_1$ and chooses an action by solving $\max\limits_{a_2 \in A_2} u_2(a_1, a_2)$. Assume it has a unique solution, denoted by $R_2(a_1)$. 

Knowing player 2's best response, player 1 should then solve $\max\limits_{a_1 \in A_1} u_1(a_1, R_2(a_1))$ as its action in the first stage. Assume it has a unique solution, $a_1^*$. 

We call $(a_1^*, R_2(a_1^*))$ the **backwards-induction outcome** of the game.

**Example 2.1** ^90cc5c

![[4264-example-2.1.png]]

A dynamic game of complete and perfect information can be easily represented by a **game tree** (as shown above). In Example 2.1, the game begins with a **decision node** for player 1. After 1's choice of L or R, 2's decision node is reached. A **terminal node** is reached after 2's move, and payoff is received.

Here, $(R, (R', L'))$ is the backwards-induction outcome.  Here $(R', L')$ strategy by player 2 means to play $R'$ if player 1 plays $L$ and to play $L'$ if player 1 plays $R$.

### Stackelberg Model of Duopoly

Consider a dominant firm moving first and a follower moving second.
1. Firm 1 chooses a quantity $q_1 \ge 0$.
2. Firm 2 observes $q_1$ and then chooses a quantity $q_2 \ge 0$.
3. The payoff to firm $i$ is $\pi_i (q_1, q_2) = q_i[P(q_1 + q_2) -c]$ where $P(Q) = a - Q$ if $Q < a$ else 0.

The backwards-induction solution is $(\frac{a-c}{2}, \frac{a-c}{4})$. This ended up making firm 2 worse off. Having firm 1 know that firm 2 knows $q_1$ hurts firm 2.

This is an important difference between single-person decision and multi-person decision problems. In single-person decision theory, having more info can never make the decision maker worse off. In game theory, however, having more info (or more precisely, ==having it known to other players that one has more info) can make a player worse off.==

## 2.2 Two-Stage Games of Complete but Imperfect Information

1. Players 1 and 2 simultaneously choose action $a_1$ and $a_2$.
2. Players 3 and 4 observe the outcome of the first stage $(a_1, a_2)$ and then simultaneously choose action $a_3$ and $a_4$
3. Payoffs are $u_i(a_1, a_2, a_3, a_4)$ for $i = 1, 2,3, 4$.

For each given $(a_1, a_2)$, players 3 and 4 will try to find the NE in stage 2. Assume there's a unique NE $(a_3^*, a_4^*)$. Now, players 1 and 2 will try to find NE in stage 1 with payoff $u_i (a_1, a_2, a_3^*(a_1, a_2), a_4^*(a_1, a_2))$. Suppose $(a_1^*, a_2^*)$ is the unique NE. Then $(a_1^*, a_2^*, a_3^*(a_1^*, a_2^*), a_4^*(a_1^*, a_2^*))$ is called the **subgame-perfect outcome** of the 2-stage game.

### Applications

**Bank Runs**

The bank-run game shows that a bank run might happen as an equilibrium phenomenon. If investor 1 believes that investor 2 will withdraw before the investment matures, then investor 1's best response is to withdraw as well, although both investors would be better off if they waited until the investment matures before withdrawing.

**Tariff Game**

1. Two governments simultaneously choose tariff $t_1$ and $t_2$
2. Two firms simultaneously chooses the amount for home consumption $h_i$ and export $e_i$.
3. If the total quantity on the market in country $i$ is $Q_i = h_i + e_j$, then the market price $P_i(Q_i) = a - Q_i$. The firm has constant marginal cost $c$ and need to pay $t_je_i$ to government $j$.
4. The payoff to firm $i$ is its profit $\pi_i(t_i, t_j, h_i, e_i, h_j, e_j) = [a - (h_i + e_j)]h_i + [a - (h_j + e_i)]e_i - c(h_i + e_i) - t_je_i$ and the payoff to government $i$ is $w_i(t_i, t_j, h_i, e_i, h_j, e_j) = Q_i^2 / 2 + \pi_i(t_i, t_j, h_i, e_i, h_j, e_j) + t_i e_j$. 

The subgame perfect outcome is $t_1 = t_2 = \frac{a-c}{3}$, $h_1 = h_2 = \frac{4(a-c)}{9}$ and $e_1 = e_2 = \frac{a-c}{9}$. But this is not socially optimal. If $t_1 = t_2 = 0$, then this is exactly Cournot's model and $Q_i = \frac{2(a-c)}{3}$ which means lower price for the customer.

## 2.3 Dynamic Games of Complete but Imperfect Information

### Extensive-Form Representation of Games

**Def.** The **extensive-form representation** of games specifies
1. the players in the game
2. when each player has the move, what actions can they take, what knowledge do they have upon taking the move
3. the payoff received by each player for each combination of moves that could be chosen

**Def.** A **strategy** for a player is a complete plan of actions. It specifies a feasible action for the player in every contingency in which the player might be called on to act. In other words: feasible action for each information set.

Remark
- In [[MA4264#1 Static Games with Complete Information]] , player $i$'s strategy space $S_i$ is simply the action space $A_i$. 
- In repeated games, a player's strategy specifies the action the player will take in each stage **for each possible history** of play through the previous stages.

When information is not perfect, some previous moves are not observed by the player with the current move. To present this kind of ignorance of previous move, we introduce the notion of a player's information set.

**Def.** An **information set** for a player is a collection of decision nodes satisfying:
1. The player needs to move at every node in the information set.
2. When the play of the game reached a node in the information set, the player with the move
does not know which node in the set has (or has not) been reached.

Note:
- The second point implies that all nodes in the same information set should have the same set of feasible actions (otherwise it's possible to differentiate the decision nodes)
- In an extensive-form game tree, a collection of decision nodes which constitutes an information set is connected by a dotted line.
- The number of actions listed in a strategy when representing in NF = the number of unique information sets, e.g. in Example 2.1 there are 2 different information sets for player 2, so the strategy is $L'L'$, where as in Example 2.2, there are only 1 information set for player 2, so strategy is $L_2$ .

With the definition of information set, we can define the game to have **imperfect information** if there is at least one nonsingleton information set.

![[4264-prisoners-extensive-form.png]]

Furthermore, static game of complete information can now be represented as dynamic games of complete but imperfect information.


### Equilibrium vs Outcome

![[MA4264#^461de6]]


In this game, $(a_1^*, R_2(a_1^*))$ is the backwards-induction **outcome**, whereas $(a_1^*, R_2(\cdot))$ is one possible Nash **equilibrium**. Note that: 
1. $R_2(a_1^*)$ is an **action**, whereas $R_2(\cdot)$ is a **strategy**
2. $R_2(\cdot)$ is a function and $R_2(a_1^*)$ is the value of function $R_2$ at $a_1^*$
3. In a NE $(s_1^*, s_2^*)$, $s_1^*$ maximize $u_1(a_1, s_2^*(a_1))$ for all $a_1$, but $s_1^*$ do not necessarily maximize $u_1(a_1, R_2(a_1))$. In other words, there can be many NE that is not a backwards-induction outcome. Example: $(L, (R', R'))$ in [[MA4264#^90cc5c|Example 2.1]]

Similarly, In [[MA4264#2 2 Two-Stage Games of Complete but Imperfect Information]], we have $(a_1^*, a_2^*, a_3^*(a_1^*, a_2^*), a_4^*(a_1^*, a_2^*))$ as the subgame-perfect outcome, and $(a_1^*, a_2^*, a_3(\cdot, \cdot), a_4(\cdot, \cdot))$ as a NE.

## 2.4 Subgame Perfect NE

**Motivation: Bad NE**

$(L, (R', R'))$ in [[MA4264#^90cc5c|Example 2.1]] can be thought of as player 2 threatening to play $R'$ if player 1 plays $R$. But even if plays $R$, player 2 will not play $R$ (won't carry out the threat) as it is suboptimal for him. Hence this threat is not credible. ^c32632

To rule out bad NE such as $(L, (R', R'))$, we define a stronger solution called subgame-perfect NE.

**Def 2.4** A **subgame** in an extensive-form game
1. begins at a decision node $n$ that is a singleton information set but is not the game's first decision node
2. includes all the decision and terminal nodes following node $n$ in the game tree.
3. doesn't cut any information sets.

In other words, a subgame is a piece of a game that remains to be played beginning at any point at which the complete history of the game thus far is common knowledge among the players.

**Def 2.5** (Selten, 1965). A NE is **subgame-perfect** if the players' strategies constitute a NE in every subgame.

Remark. It can be shown that any finite dynamic game of complete info has a subgame-perfect NE, perhaps in mixed strategies.

**Result.** 
- A NE need not be a subgame-perfect NE.
- NE that rely on non-credible threats or promises can be eliminated by the requirement of subgame perfection.

## 2.5 Sequential Bargaining

Similar to [[MA4264#^461de6|2.1A]]. Let's first analyze a three-preiod bargaining model.

Two players $A$ and $B$ are bargaining over one dollar. They alternate in making offers: 
1. $A$ proposes to take a share $s_1$ of the dollar, leaving $1-s_1$ to $B$.
2. If $B$ rejects the proposal, $B$ can then propose to take a share $1 - s_2$ of the dollar, leaving $s_2$ to $A$.
3. If $A$ rejects the proposal, then $A$ will receive $s$ of the dollar and $B$ receive $1-s$ where $s$ is determined externally.

The catch here is that the players are impatient and they discount payoffs received in later periods by a factor of $\delta$ per period. (This makes sense if we account the time-value of money)

Using backwards induction:
1. If we reach the second period, $B$ will propose $s_2 = \delta s$. (Otherwise $A$ will just reject and receive $s$ in the third period)
2. Since $A$ can solve $B$'s second-period problem, the optimal amount is $s_1 = 1 - \delta (1 - \delta s)$.

Suppose, we now want to extend this into infinite-period bargaining (**Rubinstein's model**, no protracted negotiations) . Let $s_H$ be the highest possible payoff for $A$, notice that players can regard these payoffs as a settlement in period 3, and then they play a three-period game. From the above results, player A should offer $1 - \delta(1 - \delta \cdot s_H)$. Combining, we have $s_H = 1 - \delta(1 - \delta \cdot s_H) \leftrightarrow s_H = 1 / (1 + \delta)$.

(T5 Q1) With similar reasoning, if the discount factors are different, namely $\delta_1$ for player 1 and $\delta_2$ for player 2, we can show that the backwards-induction outcome is $\left( \frac{1 - \delta_2}{1 - \delta_1\delta_2}, \frac{\delta_2(1 - \delta_1)}{1 - \delta_1\delta_2} \right)$.

### Finitely Repeated Games

Def. Given a stage game $G$, let $G(T)$ denote the **finitely repeated** game in which $G$ is palyed $T$ times, with the outcomes of all preceding plays observed before the next play begins. The payoffs for $G(T)$ are simply sum of the payoffs from the $T$ stage games.

Result.
- If the stage game $G$ has a unique NE, then for any finite $T$, the repeated game $G(T)$ has a unique subgame-perfect outcome: the NE of $G$ played in every stage.

## 2.6 Infinitely repeated games

From textbook chapter 2.3A: 
- Pure-strategy NE $A = (a_1, a_2, \dots a_n)$ *Pareto-dominates* NE $B = (b_1, b_2, \dots, b_n)$ if all $n$ players unanimously prefer $A$ over $B$. Otherwise, $A$ are said to be on the *Pareto-frontier* of the game.
- The main theme of repeated games (both finite-horizon or infinitely) is that credible threats or promises about future behavior can influence current behavior.

**Def.** Let $\pi_t$ be the payoff in stage $t$. Given a discount factor $\delta \in (0,1)$ , the present value of payoffs $\{ \pi_1, \pi_2, \dots \}$ is $\sum\limits_{t=1}^\infty \delta^{t-1}\pi_t$.

**Infinitely-repeated game**

1. In the first stage, the players play stage game $G$ and receive payoffs $\pi_{1,1}$ and $\pi_{2,1}$. 
2. In the $t$-th stage, the players observe the actions chosen in the preceding $t-1$ stages and then play $G$ to receive $(\pi_{t,1}, \pi_{t,2})$. 
3. The payoffs of the infinitely repeated game is the present value of the sequence of payoffs $(\sum\limits_{t=1}^\infty \delta^{t-1}\pi_{1,t}, \sum\limits_{t=1}^\infty \delta^{t-1}\pi_{2,t})$

Note:
- If $G$ has multiple NE, then there maybe subgame-perfect outcomes where the outcome in stage $t$ is not a NE of $G$
- In an infinitely-repeated game, each subgame is identical to the original game.

Some strategies:
1. Non-cooperative strategy: play non-cooperative action $L$ in every stage.
2. Trigger strategy: plays a cooperative action $R$ in the first stage. In the $t$-th stage, if the outcome of all $t-1$ preceding stages has been $(R, R)$ then continue playing $R$. Otherwise, play non-cooperative action $L$. 

Result. If the discount factor $\delta$ is close enough to 1, then it is a subgame-perfect NE of the infinitely-repeated game for both players to adopt trigger strategy.

### Collusion between Cournot Duopolists

- In the Cournot model, both firms produce $q_C = \frac{a-c}{3}$ with profit $\pi_C = \frac{(a-c)^2}{9}$.
- Each firm colludes to produce $\frac{q_m}{2}$ each so that their joint output is the monopoly quantity $q_m = \frac{a-c}{2}$. Profits for each firm is then $\pi_i = \frac{(a-c)^2}{8}$ (better off than if they both produce $q_C$).
- If firm $i$ produces $\frac{q_m}{2}$, the best response for firm $j$ is to produce $q_d = \frac{3(a-c)}{8}$ with profit $\pi_d = \frac{9(a-c)^2}{64}$. 

Let the trigger strategy $T_i$ be to cooperate in producing $\frac{q_m}{2}$ until one of the firms deviates, and after that producing $q_C$ forever.

Consider the infinitely-repeated game based on the Cournot stage game with a discount factor $\delta$.

Then $(T_i, T_j)$ is an NE iff $\delta \ge \frac{9}{17}$. 
Proof: Suppose firm $i$ has adopted the trigger strategy. 

If the quantity other than $\frac{q_m}{2}$ has been produced before, then firm $i$ will produce $q_C$ in this period. The best response for firm $j$ is to choose $q_C$ too from this period onwards since $(q_C, q_C)$ is the unique NE for the stage game. 

If in all previous stages, $\frac{q_m}{2}$ has been produced by both firms, then $T_j$ is the best response strategy for firm $j$ only if the present value of deviating $\pi_D + \frac{\delta\pi_C}{1 - \delta} \le \frac{1}{1 - \delta} \cdot \frac{\pi_m}{2}$, which is the present value of collaborating (never deviates).

Note: There are further discussion in the textbook on Friedman's Theorem (stated below without discussion), optimal quantity produced in the case of $\delta < \frac{9}{17}$ and Abreu's two-phase strategy which can be more optimal than the trigger strategy. 

**Def.** 
- $(x_1, \dots, x_n)$ a feasible payoff of a stage game $G$ if they are a weighted average of the pure-strategy payoffs of $G$.
- Let the **average payoff** be $(1 - \delta)$ of the present value of payoffs.

**Thm.** (Friedman, 1971) Let $G$ be a finite, static game of complete information. Let $(e_1, \dots, e_n)$ denote the payoffs from a NE of $G$. Let $(x_1, \dots, x_n)$ denote any other feasible payoffs. If $x_i > e_i$ for every player $i$ and if $\delta$ is sufficiently close to 1, then there exists a subgame-perfect NE of the infinitely repeated game with $G$ as stage game that achieves $(x_1, \dots, x_n)$ as the average payoff.

# 3 Static Games of Incomplete Information

Games of incomplete information are also called **Bayesian games**

In such games, at least 1 player is uncertain about another player's payoff function.

## 3.1 Cournot competition under asymmetric information

Consider the Cournot duopoly model, except that firm 1's cost is $cq_1$ while firm 2's cost is $c_H q_2$ with probability $\theta$ or $c_Lq_2$ with probability $1-\theta$ where $c_l < c_H$ are low cost and high cost, respectively.

Note that the information is asymmetric : firm 1's cost is known by both, but firm 2's cost function is only completely known to itself.

The two firms simultaneously choose $(q_1^*, q_2^*(c_H), q_2^*(c_L))$ where
- $q_1^*$ maximizes its expected profit $\theta[a - q_1 - q_2^*(c_H) -c] + (1- \theta)[a - q_1 - q_2^*(c_L) - c]q_1$ ,
- $q_2^*(c_H)$ maximizes $[a - q_1^* - q_2 - c_H]q_2$
- $q_2^*(c_L)$ maximizes $[a - q_1^* - q_2 - c_L]q_2$. 

The equilibrium of the game is then $q_1^* = \frac{a - 2c + \theta c_H + (1 - \theta) c_L}{3}$, $q_2^*(c_H) = \frac{a - 2c_H + c}{3} + \frac{1 - \theta}{6}(c_H - c_L)$ and $q_2^*(c_L) = \frac{a - 2c_L + c}{3} - \frac{\theta}{6}(c_H - c_L)$.

Remark. Firm 2 produces more than the Cournot quantity under perfect information, i.e. $\frac{a-2c_H + c}{3}$,  when it gets $c_H$ because it knows that firm 1 would account for the possibility of $c_L$ and hence produce less than if it knows with certainty that firm 2 gets $c_H$. 

## 3.2 Static Bayesian Games and Bayesian NE

**Def 3.1** The **normal-form representation** of an $n$-player static Bayesian game specifies the players' action spaces $A_1, \dots, A_n$, their type spaces $T_1, \dots, T_n$, their beliefs $P_1, \dots, P_n$ and their payoff functions $u_1, \dots, u_n$. 
- Player $i$'s type $t_i \in T_i$ is privately known by player $i$
- $t_i$ determines player $i$'s payoff function $u_i( a_1, \dots, a_n ; t_i)$. 
- Player $i$'s belief $P_i(t_{-i} \mid t_i)$ describes $i$'s uncertainty about the $n-1$ players' possible types $t_{-i}$ given his own type $t_i$. 

The timing of a static Bayesian game:
1. Nature draws a type vector $t = (t_1, \dots, t_n)$, $t_i \in T_i$ and reveals $t_i$ to player $i$
2. Players simultaneously choose actions, player $i$ choosing $a_i \in A_i$.
3. Payoffs $u_i(a_1, \dots, a_n ; t_i)$ are received.

Suppose Nature draws $t = (t_1, \dots, t_n)$ from a prior probability distribution $P(t)$. Then the **belief** $P_i(t_{-i} \mid t_i)$ about other players' types can be computed using Bayes' rule.

**Def 3.2** In the static Bayesian game $G$, a **strategy** for player $i$ is a function $s_i : T_i \rightarrow A_i$. 

Remark. Unlike (both static and dynamic) games of complete information, in a Bayesian game, the strategy spaces are not given in the normal-form representation of the game.

**Def 3.3** In the static Bayesian game $G$, the strategies $s^* = (s_1^*, \dots, s_n^*)$ are a (pure-strategy) **Bayesian NE / BNE** if for each player $i$ and for each of $i$'s type $t_i \in T_i$, the action $s_i^*(t_i)$ is the maximizer over $A_i$ of $$E_{t_{-i}}[u_i(a_i, s_{-i}^*(t_{-i}); t_i)] = \sum\limits_{t_{-i} \in T_{-i}} P_i(t_{-i} \mid t_i) \, u_i(a_i, s_{-i}^*(t_{-i}); t_i)$$
Remark. In a general finite (action spaces) static Bayesian game, a Bayesian NE equilibrium exists, perhaps in mixed strategies.

## 3.5 First-Price Sealed-Bid Auction

Suppose there are 2 bidders. The bidders' valuations $v_i$ for a good are independently and uniformly distributed on [0, 1]. Bidders submit their bids $b_i$ simultaneously. The higher bidder wins the good and pays her bidding price; the other bidder gets and pays nothing. In the case that $b_1 = b_2$, the winner is determined by a flip of a coin.

This can be expressed as a static Bayesian game $G = \{ A_1, A_2; T_1, T_2; P_1, P_2, u_1, u_2 \}$ where $A_1 = A_2 = [0, \infty)$ (bids $b_i \in A_i$) ; $T_1 = T_2 = [0, 1]$ (valuations $v_i \in T_i$); $P_i(v_j)$ is the uniform distribution on [0, 1]. For any $v_i \in T_i$, player $i$'s playoff is $u_i (b_1, b_2; v_i)$ = $v_i - b_i$ if $b_i > b_j$, $\frac{v_i-b_i}{2}$ if $b_i = b_j$, and 0 if $b_i < b_j$. Player $i$'s strategy is a function $b_i(v_i)$ from [0, 1] into $[0, \infty)$.

There may be many BNE of the game. For simplicity, we only look for equilibria in the form of linear functions: $b_i(v_i) = a_i + c_iv_i$ where $1 > a_i \ge 0, c_i > 0$. Note that an equilibrium must still satisfy that it is better than all functions $b_i : [0, 1] \rightarrow [0, \infty)$. 

Note that since $v_i$ is a continuous distribution $\mathbb{P}[b_i = a_j + c_jv_j] = 0$. For any given $v_i \in [0, 1]$, player $i$'s best response $b_i(v_i)$ maximizes $(v_i - b_i) \mathbb{P}[b_i > a_j + c_jv_j]$. We can also restrict $b_i \in [a_j, a_j + c_j]$. Thus, the player $i$'s best response is $b_i(v_i) = a_j$ if $v_i \le a_j$, $(v_i + a_j)/2$ if $a_j < v_i \le a_j +2c_j$ and $a_j + c_j$ if $v_i > a_j + 2c_j$.  

Since we want the equilibrium strategy $b_i$ to be a linear function on [0, 1], there are only 3 cases, i.e. $[0, 1] \subseteq (-\infty, a_j]$, $[a_j, a_j + 2c_j]$, or $[a_j + 2c_j, \infty)$. It is easy to see only the middle case holds. This leads to $b_i(v_i) = v_i / 2$. 

For $n$ bidders, a strategy with $b_i(v_i) = \frac{n-1}{n} v_i$ is a BNE.  

The expected revenues for the seller is $\frac{n-1}{n + 1}$. 

One might wonder whether there are other BNE of this game, and how equilibrium bidding changes as the distribution of the bidders' valuations changes. Neither of these questions can be answered using the technique just applied (positing linear strategies and deriving coefficients). 

Under the assumption that the players' strategies are strictyle increasing and differentiable it can be shown that the unique *symmetric* BNE is the linear equilibrium already derived.

## 3.6 Second-Price Sealed-Bid Auction

There are $n$ potential bidders, with valuations $v_1, \dots, v_n$ for an object. Bidders know their own valuation but do not know the other bidders' valuations. The bidders simultaneously submit bids $b_i \in [0, \infty)$. The highest bidder wins the object and **pays the second highest bid** and the other bidders pay nothing. If more than one bidders bid the highest price, the object is allocated randomly among them. Let $r_i = \max\limits_{j \ne i} b_j$. The bidder $i$'s payoff function is $(v_i - r_i) / k$ if $i$ is one of $k$ winner(s), and 0 otherwise.

First note that the stategy $b_i^*(v_i) = v_i$, i.e. bidding her valuation, weakly dominates any other strategy $b_i$. This is because if a player has valuation $v_i$, the maximum payoff she can receive regardless of strategy $b_i$ is $\max(v_i - r_i, 0)$. 

**Proposition 3.1** Let $(s_1^*, \dots, s_n^*)$ be strategies in a static Bayesian game. If for any $t_i \in T_i, a_i \in A_i$, and $a_{-i} \in A_{-i}$, $s_i^*(t_i)$ weakly dominates every $a_i \in A_i$, then $(s_1^*, \dots, s_n^*)$ is a BNE.

From Proposition 3.1, we conclude that bidding one's valuation is a BNE.

The expected revenues for the seller is $\frac{n-1}{n+1}$. 

## 3.7 Double Auction

There are 2 players: a buyer and a seller. The buyer's valuation for the seller's good is $v_b$ and the seller's is $v_s$. The valuations are private information and are drawn from certain independent distributions on [0, 1]. 

The seller names an asking price, $p_s$, and the buyer simultaneously names an offer price $p_b$. If $p_b \ge p_s$, then trade occurs at price $p = \frac{p_b + p_s}{2}$; otherwise, no trade occurs.

There are many BNE of this game, but we will consider 2 types.

### One-Price equilibria

For any value $x \in [0,1]$ which is given exogeneously and is known to both players, the **one-price strategies** are as follows:
- The buyer offers $x$ if $v_b \ge x$ and 0 (not trading) otherwise.
- The seller demands $x$ if $v_s \le x$ and 1 (not trading) otherwise.

Given the buyer's strategy, the seller's choices amount to trading at $x$ or not trading. The seller's strategy is a best response because those seller-types that prefer trading at $x$ do so, and vice-versa. So these strategies are indeed BNE.

![[4264-double-auction-one-price.png|300]]

Trade would actually be beneficial for both players at a certain price (i.e. efficient) for all pairs satisfying $v_b \ge v_s$. But, it doesn't occur when $v_b < x$ or when $v_s > x$. 

### Linear Strategies

Now, we look for *linear* equilibrium strategies $p_i(v_i) = a_i + c_iv_i$ with $a_i \ge 0$ and $c_i > 0$. Solving for the maximizer of $$E_{v_s} \pi_b(p_b, p_s(v_s) \mid v_b) = \int\limits_{a_s \le p_s(v_s) \le p_b} \left( v_b - \frac{p_b + p_s(v_s)}{2} \right) dv_s$$, we have $p_b = \frac{2}{3}v_b + \frac{1}{3}a_s$. Similarly, we will get $p_s = \frac{2}{3}v_s + \frac{1}{3}(a_b + c_b)$. 

Therefore the linear equilibrium strategies are $p_b(v_b) = \frac{2}{3}v_b + \frac{1}{12}$ and $p_s(v_s) = \frac{2}{3}v_s + \frac{1}{4}$.  The trade occurs iff $p_b \ge p_s$, i.e. iff $v_b \ge v_s + \frac{1}{4}$. 

**Comparison between the 2 strategies**

- In both cases, the most valuable possible trade, i.e. $v_s = 0$ and $v_b = 1$ occurs. 
- The one-price equilibrium misses some valuable trades (such as $v_s = 0$ and $v_b = x - \epsilon$ ), and achieves some trades that are worth next to nothing (such as $v_s = x - \epsilon$ and $v_b = x + \epsilon$ )
- The linear equilibrium, in contrast, misses all trades worth next to nothing but achieves all trades worth at least 1/4.
- (Myerson, Satterthwaite, 1983) shows that for the uniform valuation distributions, the linear equilibrium yields higher expected gains for the players than any other BNE of the double action.  

## 3.8 Mixed Strategies Revisited

A [[MA4264#Mixed Strategies|mixed-strategy NE]] in a game of complete information can almost always be interpreted as a pure-strategy BNE in a closely related game with a little bit of incomplete information. Put another way, the crucial feature of a mixed-strategy NE is not that player $j$ chooses a strategy randomly, but rather that player $i$ is uncertain about player $j$'s choice.

**Revisiting Battle of the Sexes game**

Suppose Mary and Peter are not completely sure about each other's payoff. If both attend Opera, Mary's payoff is $2 + t_m$. If both attend Football, Peter's payoff is $2 + t_p$, where $t_m$ is privately known by Mary and $t_p$ is privately known by Peter, and $t_m$ and $t_p$ are independently drawn from a uniform distribution on [0, x]. 

This can be expressed as a static Bayesian game $G = \{ A_m, A_p; T_m, T_p; P_m, P_p, u_m, u_p \}$ where $A_m = A_p$ = { Opera, Football }; $T_m = T_p = [0, x]$, $P_m(t_p) = P_p(t_m) = \frac{1}{x}$ are density functions. In general, Mary's and Peter's strategies are functions from $[0, x]$ to $\{ O, F \}$.

Let $\delta_m$ be the probability that Mary plays Opera, and $\delta_p$ be the probability that Peter plays Football.
- Mary playing Opera is optimal iff $(2 + t_m)(1 - \delta_p) \ge \delta_p$, i.e. $s_m(t_m) = O$ if $t_m \ge m = \frac{\delta_p}{1 - \delta_p} - 2$ and F otherwise.
- Peter playing Opera is optimal iff $(2 + t_p)(1 - \delta_m) \ge \delta_m$, i.e. $s_p(t_p) = F$ if $t_p \ge p = \frac{\delta_m}{1 - \delta_m} - 2$ and O otherwise.

At the best responses, all $t_m \ge m$ plays Opera, so $\delta_m = \frac{x-m}{x}$. It follows that $p = \frac{x}{m} - 3$. Similarly, $m = \frac{x}{p} - 3$. We see that the best response strategy is uniquely defined by a number, e.g. $s_p$ is defined by $p$. Hence $(s_m^*, s_p^*)$ or $(m^*, p^*)$ is BNE when $p^* = m^* = \frac{\sqrt{9 + 4x} - 3}{2}$. 

If $x \rightarrow 0$, $\delta_m^* = \delta_p^* \rightarrow \frac{2}{3}$. Thus, as the incomplete information disappears, the players' behavior in this pure-strategy BNE of the incomplete-information game approaches their behavior in the mixed-strategy NE in the original game of complete information.

# 4 Dynamic Games of Incomplete Information

Motivation.

![[4264-example4.1.png]]
There are 2 NE: $(L, L')$ and $(R, R')$ . Both are also subgame-perfect NE as there is no subgames. However $(R, R')$ is still based on a [[MA4264#^c32632|non-credible threat]] and we would like to eliminate such NE.

A good solution in a dynamic game should choose an "optimal" action in every stage. However, in the above game, player 2 doesn't know which node in the information set is reached -> doesn't know which payoff to use to choose an optimal action. So, we assume that player 2 has a **belief** about probabilities with which nodes in the information set are reached, and we calculate the expected payoff based on this probability distribution.

Assume player 2 believe that $L$ has been played by player 1 with probability $p$. For all values of $p$, $L'$ dominated $R'$ for player 2, hence $(R, R')$ is not optimal and can be eliminated. 

In the above example, $L'$ is the unique maximizer. Usually however, different beliefs may result in different optimal actions. To guarantee that these "optimal" actions are desirable, ==our belief must be **consistent** with all players' strategies== (by Bayes' rule)

Definition. A **subsequent strategy** is a complete plan of action covering every contingency that might arise after the given information set is reached.

**Def 4.1** A **perfect Bayesian equilibrium** (PBE) consists of strategies and beliefs satisfying:
 1. Given their beliefs, the players' strategies must be sequentially rational. In other words: At each information set, given the player's belief and other players' subsequent strategies, the action taken by the player with the move (and the player's subsequent strategy) must be optimal.
 2. At every information set, beliefs are determined by Bayes' rule and the players' strategies whenever possible.

Remark. 
- The strategy profile in any PBE is a NE.
- If an information set is not reached by a strategy, the belief can take any value.

## 4.2 Signaling Games

A signaling game is a dynamic game of incomplete information involving 2 players: a sender $S$, and a receiver $R$. The timing of the game is as follows:
1. Nature draws a type $t_i$ for the Sender from a set of feasible types $T = \{ t_1, \cdots, t_I \}$ according a probability distribution $P(t_i)$.
2. The sender observes $t_i$ and chooses a message $m_j$ 
3. The receiver observes $m_j$ (but not $t_i$) and chooses an action $a_k$.
4. Payoffs are given by $U_S(t_i, m_j, a_k)$ and $U_R(t_i, m_j, a_k)$.

Consider a simple signaling game $T = \{t_1, t_2 \}, A = \{a_1, a_2 \}, P(t_1) = p, M = \{ m_1, m_2 \}$. 

![[4264-signaling-game.png]]
The Sender has 4 strategies: $(m_i, m_j)$ with $i, j \in \{1, 2\}$ where $(m_i, m_j)$ means that the Sender sends $m_i$ if Nature draws $t_1$ and sends $m_j$ if Nature draws $t_2$. We call $(m_1, m_1), (m_2, m_2)$ strategies **pooling** and $(m_1, m_2), (m_2, m_1)$ strategies **separating**.

The Receiver has 4 strategies: $(a_i, a_j)$ with $i, j \in \{1, 2\}$ where $(a_i, a_j)$ means that the Receiver plays $a_i$ if the Sender sends $m_i$  and plays $a_j$ if the Sender sends $m_j$

After observing any message $m_j$ , R must have a belief $\mu(t_i \mid m_j)$ about which types could have sent $m_j$.

**Sequential rationality:** 
- For each $m_j$, R's action $a^*(m_j)$ maximizes R's expected utility given the belief $\mu(t_i, m_j)$, i.e. $\sum\limits_{t_i}\mu(t_i \mid m_j) U_R(t_i, m_j, a_k)$.
- Similarly, for each $t_i$, S's message $m^*(t_i)$ must maximizes $U_S(t_i, m_j, a^*(m_j))$.

**Consistency:** Given S' optimal strategy $m^*$, let $T_j$ be all types $t_i$ for which $m^*(t_i) = m_j$. If $T_j = \emptyset$,  $\mu(t_i \mid m_j)$ can take any value. Otherwise $\large\mu(t_i \mid m_j) = \frac{P(t_i)}{\sum_{t \in T_j} P(t)}$

**Def 4.2** A pure-strategy PBE in a signaling game is a pair of strategies $m^*(t_i)$ and $a^*(m_j)$ and a belief $\mu(t_i \mid m_j)$ satisfying the sequential rationality and consistency.

## 4.3 Job-Market Signaling

In the model of job-market signaling, the sender is a worker, the receiver is the market of prospective employers, the type is the worker's productive ability $\eta$ (high: $\eta_H$ or low: $\eta_L$) with equal probability chosen by Nature, the message is the worker's education choice $e$ (college: $e_c$ or school: $e_s$), and the action is the wage $w$ paid by the market (high: $w_H$ or low: $w_L$). 

The payoffs are
- $w - c(\eta, e)$ to the worker where $c(\eta, e)$ is the cost to a worker with ability $\eta$ of obtaining education $e$.
- $-(y(\eta, e) - w)^2$ to the firm that employs the worker, where $y(\eta, e)$ is the output of a worker with ability $\eta$ who has obtained education $e$. (The rational for this payoff is : competition among firms will drive expected profits to zero, and implies that wage should equal production output in the market).

**Prop 4.1.** Let $c(\eta, e) = c_1(\eta) + c_2(e)$. Assume that the workers' payoffs from playing $e_c$ and $e_s$ respectively are different. Then, there does not exist separating PBE.

### 4.5 Sequential Bargaining under Asymmetric Information

A firm and a union bargaining over wages. The amount union members earn if not employed by the firm is $w_r$. The firm's profit $\pi$ is uniformly distributed on $[\pi_L, \pi_H]$ but the true value of $\pi$ is privately known by the firm. The following analysis is simplified by assuming $w_r = \pi_L = 0$. 

The bargaining game lasts at most 2 periods. 
1. In the first period, the union makes a wage offer $w_1$. If the firm accepts, the game ends: the union's payoff is $w_1$ and the firm's is $\pi - w_1$. 
2. In the second period, the union makes a second wage offer $w_2$ (only if $w_1$ is rejected). If the firm accepts, then the union's payoff is the present values of its payoff $\delta w_2$, and $\delta(\pi - w_2)$ for the firm, where $\delta$ reflects both discounting and the reduced life of the contract remaining after the first period. Otherwise, both sides gets 0.

The unique PBE of this game:
- The union's first-period wage offer maximizes $w_1$ Prob( firm accepts $w_1$ ) + $\delta w_2$ Prob( firm rejects $w_1$ but accepts $w_2$ ). It is given as $w_1^* = \frac{(2 - \delta)^2}{2 ( 4 - 3\delta)} \pi_H$.
- If the firm's profit $\pi$ exceeds $\pi_1^* = \frac{2w_1^*}{2 - \delta}$, then the firm accepts $w_1^*$; otherwise it rejects.
- If the first-period offer is rejected, the union updates its belief about the firm's profit: the union now believes that $\pi$ is uniformly distributed on $[0, \pi_1^*]$ and offer $w_2^* = \frac{\pi_1^*}{2}$ 
- If the firm's profit $\pi$ exceeds $w_2^*$, the firm accepts; otherwise it rejects.

# 5 Cooperative Games

In cooperative games **binding agreements may be made** among the players. In addition, we assume that all payoffs are measured in the same units and that there is a **transferrable utility** which allows **side payments** to be made among the players.

Side payments may be used as inducements for some players to use certain mutually beneficial strategies. Thus, there will be a tendency for players, who have similar objectives in the game, to form alliances or coalitions. Players in a coalition will collectively generate a payoff to the coalition. Thus, the central issue is to find a fair distribution of payoffs among players.

## 5.1 Two-Person Cooperative Games

![[4264-2p-cooperative.png]]

- $H$ is constructed as pair of each players' utility functions.
- There is, generally, a set of outcomes, called the **feasible set** which can be obtained by the 2 players by acting together, e.g. $H \subset \mathbb{R}^2$.
- The **threat point** (or *status quo* or *no trade point*) $d \in H$ is the outcome that is obtained in the absence of trade. This is the amount that each player will obtain by unilateral action, whatever the other player does, i.e. the maximin value of the game for that player.


**Def 5.1** The pair $\Gamma = (H, d)$ is a two-person bargaining game if $H \subset \mathbb{R}^2$ is compact and convex, $d \in H$ and $H$ contains at least one element such that $u >> d$ .

**Def 5.2** Let $(u, v)$ and $(u', v')$ be 2 payoff pairs. We say $(u, v)$ **dominates** $(u', v')$ if $u \ge u'$ and $v \ge v'$. Payoff pairs which are not dominated by another pair are said to be **Pareto optimal**

Among all feasible outcome of the game, we find that the more 1 player gets, the less the other player will be able to get (though not necessarily so). Now, how much will one player be willing to give the other? How little will he be willing to accept as the price of his cooperation?

So given a set $H$ and its maximin values $d$, we want a rule which assign a "bargaining solution". While the outcome of any particular case will depend on the personalities and bargaining abilities of the 2 players, the axioms in the following definition is reasonable. 

Denote the set of all two-person bargaining games as $W$. 

**Def 5.3** The **Nash bargaining solution** is a mapping $f: W \rightarrow \mathbb{R}^2$  such that $f(H, d) = (f_1(H, d), f_2(H,d))$ satisfying the following axioms:
1. Feasibility: $f(H, d) \in H$
2. Individual Rationality: $f(H, d) \ge d$ for all $(H, d) \in W$.
3. Pareto Optimality: $f(H, d)$ is Pareto optimal.
4. Invariance under Linear Transformations: Let $a_1, a_2 > 0$ , $b_1, b_2 \in \mathbb{R}$ and $(H, d), (H', d') \in W$ where $d_i' = a_id_i + b_i$ and $H' = \{x \in \mathbb{R}^2 \mid x  = ay + b, y \in H \}$. Then, $f_i(H_i',d_i') = a_if_i(H,d) + b_i$.    
5. Symmetry: If $(H, d) \in W$ satisfies $d_1 = d_2$ and $(x_1, x_2) \in H$ implies $(x_2, x_1) \in H$, then $f_1(H,d) = f_2(H,d)$. 
6. Independence of Irrelevant Alternatives: If $(H, d), (H', d') \in W, d = d', H \subset H'$ and $f(H', d') \in H$, then $f(H, d) = f(H', d')$. 

**Thm 5.1** A game $(H, d) \in W$ has a unique Nash solution $u^*= f(H, d)$ satisfying conditions 1-6 iff $(u_1^* - d_1)(u_2^* - d_2) > (u_1 - d_1)(u_2 - d_2)$ for all $u \in H, u \ge d$ and $u \ne u^*$.

## 5.2 n-person Cooperative Games

In the noncooperative case, $n$-person games is merely a generalization of the 2-person case. In cooperative games, however, a new idea appears: coalitions.

In two-person games, there is only 1 possible coalition. In the $n$-person games, there are many possible coalitions -> different members of the coalition must reach some sort of equilibrium or stability.

Consider the three-person game, where if any 2 of them succeed in forming a coalition, then the third player must pay each of them 1 unit. If no 2-player coalition is formed, then there is no payoff at all. Here, $(-2,1,1),(1,-2,1),(1,1,-2)$ seem to be a "natural" result. The payoff $(0,0,0)$ is also some sort of solution to the game.

Now let us suppose that if the coalition $(2,3)$ is formed, player 1 must pay 1.1 units to 2 and 0.9 unit to 3. This would seem to improve 2's outlook, however now 3 is incentivized to form coalition $(1,3)$ instead -> 2 is in a worse position than before. To remedy this, he might give a side payment of 0.1 unit to 3.

**Def 5.4** For an $n$-person game with the set of players $N = \{ 1, 2, \dots, n \}$, any nonempty subset of $N$ (including $N$ itself) is called a **coalition**. For each coalition $S$, the **characteristic function** $v$  of the game gives the amount $v(S)$ that the coalition $S$ can be sure of receiving. The game is denoted by $\Gamma  = (N, v)$. 

**Assumption 5.1** We assume the characteristic function $v$ satisfies
1. $v(\emptyset) = 0$.
2. Super-additivity: For any disjoint coalitions $K, L \subset N$, $v(K \cup L) \ge v(K) + v(L)$.   ^4e9350

Remark. We can view $v(S)$ as the amount of utility that members of $S$ can obtain from the game, whatever the remaining players may do. 

Without inquiring into the particular coalition structure obtained, we would like to know the possible (and fair) payoff vectors, i.e. how the total utility $v(N)$ of the $n$ players should be divided.

**Def 5.5** An **imputation** in the game $(N, v)$ is a payoff vector $x = (x_1, \dots, x_n)$ satisfying
1. Group Rational: $\sum\limits_{i=1}^n x_i = v(N)$.
2. Individually Rational: $x_i \ge v(\{ i \})$. 

Let $I(N,v)$ denote the set of all imputations of the game $(N, v)$.

**Def 5.6** Let $x, y \in I(N, v)$ and let $S$ be a coalition. $x$ **dominates $y$ via $S$** ($x \succ_S y$) if 
1. $x_i > y_i$ for all $i \in S$ (Read: all members of S prefers $x$ over $y$)
2. $\sum\limits_{i \in S} x_i \le v(S)$.  (Read: S are capable of obtaining $x$)

$x$ **dominates** $y$ ($x \succ y$) if there is any coalition $S$ s.t. $x \succ_S y$.

Remark: 
- Given $x$ and $y$ are both imputations, i.e. have the same sum of components, there will be players who prefer $x$ to $y$ and others who prefer $y$ to $x$. Hence, it is not possible to achieve consensus. What is needed is that the players who prefer $x$ to $y$ be actually strong enough to enforce the choice of $x$.
- A dominated imputation $x$ is unstable. If $x \prec_S y$,  members in $S$ can gain $y_i$ instead of $x_i$ if they form coalition $S$. 

**Def 5.7** The set of all undominated imputations for a game $(N, v)$ is called the **core**, denoted by $C(N, v)$. 

**Thm 5.2** $C(N, v)$ is the set of all $n$-vectors $x$ satisfying
1. $\sum\limits_{i \in S} x_i \ge v(S)$ for all $S \subset N$.
2. $\sum\limits_{i \in N} x_i = v(N)$. 

Remark. The core of the game $(N, v)$ is nonempty iff $v(N) \ge \min\limits_{x \in \mathbb{R}^n} \sum\limits_{i = 1}^n x_i$ such that $\sum\limits_{i \in S} x_i \ge v(S)$ for every $S \subset N, S \ne N$. 

### Some Special Games

**Def 5.8** A game $(N, v)$ is **constant-sum** if for all $S \subset N$, $v(S) + v(N-S) = v(N)$. 

**Def 5.9** A game $(N, v)$ is **essential** if $v(N) > \sum\limits_{i \in N} v(\{i\} )$. It is inessential otherwise.
**Thm 5.3** If $(N,v)$ is an inessential game, then for any coalition $S$, $v(S) = \sum\limits_{i\in S} v(\{i\})$. 
Corollary. If $(N, v)$ is inessential, then it is constant sum.

**Thm 5.4** If a game $(N, v)$ is constant-sum, then its core is either empty or a singleton $\left\{ \left( v(\{ 1 \}), \dots, v(\{ n \}) \right) \right\}$.

Collorary. If $(N, v)$ is an inessential game, then $C(N, v) = \left\{ \left( v(\{ 1 \}), \dots, v(\{ n \}) \right) \right\}$, is a singleton.

Remark. Called "inessential" because only 1 reachable imputation. Can be interpreted as coalitions doesn't make the returns better anyway :D

Collorary. If $(N, v)$ is both essential and constant-sum, then its core is empty.

### Strategical Equivalence

**Def 5.10** Two games $v$ and $u$ are **strategically equivalent** if there exist constants $a > 0$ and $c_1, \dots, c_n$ such that for every coalition $S$, $u(S) = av(S) + \sum\limits_{i \in S} c_i$. 

Remark. If 2 games are strategically equivalent, we can obtain one from another simply by performing a linear transformation on the utility spaces of the players.

**Lemma 5.1** Suppose that $u$ and $v$ are strategically equivalent following Def 5.10. 
1. $u$ is in(essential) iff $v$ is (in)essential.
2. $x$ is an imputation for $v$ iff $ax + c$ is an imputation for $u$, where $c = (c_1, \dots, c_n)^T$.
3. $x \succ_S y$ (w.r.t. $v$) iff $ax + c \succ_S ay + c$ (w.r.t. $u$).
4. $x \in C(N, v)$ iff $ax + c \in C(N, u)$.

**Def 5.11** A characteristic function $v$ is in $(0, 1)$-reduced form if $v(\{ i \}) = 0$ for all $i \in N$ and $v(N) = 1$. 

Special types of games:
- Symmetric games if $v(S)$ depends only on the number of elements in $S$.
- Simple games if for each coalition $S \subset N$, we have either $v(S) = 0$ (losing) or $v(S) = 1$ (winning), e.g. "voting" games in elections.

**Thm 5.5** Any essential game $(N, v)$ is strategically equivalent to a game $(N, u)$ in $(0,1)$-reduced form.

Take $a = (v(N) - \sum\limits_{i \in N} v(\{i\}))^{-1}$ and $c_i = -av(\{ i \})$. 

**Thm 5.6** Classification of small essential games in $(0,1)$-reduced form.
- Two-person game: $v(\emptyset) = v(\{ i \}) = 0, \; v(N) = 1$.
- Three-person constant-sum game. $v(\emptyset) = v(\{ i \}) = 0, \; v(N) = v(\{ i, j \}) = 1$. 
- Three-person game: There exists $a, b, c \in [0, 1]$ such that $v(\emptyset) = v(\{ i \}) = 0, \; v(\{ 1, 2 \}) = a, \; v(\{ 1, 3 \}) = b, \; v(\{ 2, 3 \}) = c, \; v(N) = 1$.

Generally the set of $n$-person games in $(0,1)$-reduced form is the set of functions $v$ defined on the subsets of $N$ such that $v(\emptyset) = v(\{ i \}) = 0, \; v(N) = 1$ and satisfies [[MA4264#^4e9350|super-additivity]].

### The Shapley Value

Given any $n$-person game $(N, v)$ , the Shapley value is an $n$-vector, denoted by $\phi(v)$ , satisfying the $i$-th component of $\phi(v)$ can be uniquely determined by  $$\phi_i(v) = \sum\limits_{S \subseteq N \backslash \{i\}} \frac{s!(n-s-1)!}{n!} (v(S \cup \{i\}) - v(S))$$ Explanation: Players come randomly. If $i$-th player arrives and finds the members of the coalition $S$ already there (this event has probability $\frac{s!(n-s-1)!}{n!}$),  he joins the coalition and receives the amount $v(S \cup \{i\}) - v(S)$, i.e. the marginal amount which he contributes to the coalition, as payoff.

**Proposition**. The Shapley value has the following desirable properties
1. Individual rationality: $\phi_i(v) \ge v(\{ i \})$ for all $i \in N$.
2. Efficiency: The total gain is distributed, i.e. $\sum\limits_{i \in N} \phi_i(v) = v(N)$
3. Dummy: If a player $i$ such that $v(S \cup \{i\}) = v(S)$ for every $S$ where $i \notin S$, then $\phi_i(v) = 0$.
4. Symmetry: If players $i$ and $j$ are such that $v(S \cup \{i\}) = v(S \cup \{j\})$ for every coalition S where $i, j \notin S$ , then $\phi_i(v) = \phi_j(v)$.
5. Additivity: If $v$ and $w$ are characteristic functions, then $\phi(v + w) = \phi(v) + \phi(w)$. 

Example 5.5 (The Shapley value of $v_A$) . Given $A \subset N$, define a game $v_A(S) = \alpha$ if $A \cap S \ne \emptyset$ and 0 otherwise. Then the Shapley value is $\phi_i(v_A) = \frac{\alpha}{|A|}$ for all $i \in A$ and 0 otherwise.

